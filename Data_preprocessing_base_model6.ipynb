{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Merge, Input, concatenate\n",
    "from keras.layers import TimeDistributed, Lambda\n",
    "from keras.layers import Convolution1D, GlobalMaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.preprocessing import sequence, text\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(327474, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11881</td>\n",
       "      <td>22926</td>\n",
       "      <td>22927</td>\n",
       "      <td>Who to download GTA San Andreas without net?</td>\n",
       "      <td>How long to become air force colonel?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75170</td>\n",
       "      <td>128697</td>\n",
       "      <td>128698</td>\n",
       "      <td>How does ito integral represent a Brownian mot...</td>\n",
       "      <td>Why are Ito integrals important?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175257</td>\n",
       "      <td>76887</td>\n",
       "      <td>4072</td>\n",
       "      <td>How can I control emotional stress?</td>\n",
       "      <td>How do I gain emotional intelligence and contr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61861</td>\n",
       "      <td>107933</td>\n",
       "      <td>44287</td>\n",
       "      <td>How did NASA get the Voyager spacecraft to int...</td>\n",
       "      <td>In Interstellar, how did Cooper (on Earth) get...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>206912</td>\n",
       "      <td>18163</td>\n",
       "      <td>17607</td>\n",
       "      <td>How do you treat canker sores or mouth ulcers?</td>\n",
       "      <td>How do you treat inflammation of the mouth wit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1    qid2                                          question1  \\\n",
       "0   11881   22926   22927       Who to download GTA San Andreas without net?   \n",
       "1   75170  128697  128698  How does ito integral represent a Brownian mot...   \n",
       "2  175257   76887    4072                How can I control emotional stress?   \n",
       "3   61861  107933   44287  How did NASA get the Voyager spacecraft to int...   \n",
       "4  206912   18163   17607     How do you treat canker sores or mouth ulcers?   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0              How long to become air force colonel?             0  \n",
       "1                   Why are Ito integrals important?             0  \n",
       "2  How do I gain emotional intelligence and contr...             1  \n",
       "3  In Interstellar, how did Cooper (on Earth) get...             0  \n",
       "4  How do you treat inflammation of the mouth wit...             1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/model_train.csv\")\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"question1\"] = data[\"question1\"].apply(lambda x: str(x))\n",
    "data[\"question2\"] = data[\"question2\"].apply(lambda x: str(x))\n",
    "data[\"question1\"] = data[\"question1\"].apply(lambda x: x.replace(\"'\", \"\"))\n",
    "data[\"question2\"] = data[\"question2\"].apply(lambda x: x.replace(\"'\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294726, 6) (32748, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train, x_valid = train_test_split(data, test_size=0.1, random_state=1992)\n",
    "print(x_train.shape, x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1_train is 33.9% complete.\n",
      "x1_train is 67.9% complete.\n",
      "x2_train is 33.9% complete.\n",
      "x2_train is 67.9% complete.\n"
     ]
    }
   ],
   "source": [
    "x1_train = []\n",
    "process_questions(x1_train, x_train.question1.values, 'x1_train', x_train)\n",
    "\n",
    "x2_train = []\n",
    "process_questions(x2_train, x_train.question2.values, 'x2_train', x_train)\n",
    "\n",
    "x1_valid = []\n",
    "process_questions(x1_valid, x_valid.question1.values, 'x1_valid', x_valid)\n",
    "\n",
    "x2_valid = []\n",
    "process_questions(x2_valid, x_valid.question2.values, 'x2_valid', x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tk_train = text.Tokenizer(num_words=200000)\n",
    "tk_train.fit_on_texts(x1_train+x2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 25\n",
    "\n",
    "x1_train = tk_train.texts_to_sequences(x1_train)\n",
    "x1_train = sequence.pad_sequences(x1_train, maxlen=max_len)\n",
    "\n",
    "x2_train = tk_train.texts_to_sequences(x2_train)\n",
    "x2_train = sequence.pad_sequences(x2_train, maxlen=max_len)\n",
    "\n",
    "x1_valid = tk_train.texts_to_sequences(x1_valid)\n",
    "x1_valid = sequence.pad_sequences(x1_valid, maxlen=max_len)\n",
    "\n",
    "x2_valid = tk_train.texts_to_sequences(x2_valid)\n",
    "x2_valid = sequence.pad_sequences(x2_valid, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76057\n"
     ]
    }
   ],
   "source": [
    "word_index = tk_train.word_index\n",
    "print(len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     1,\n",
       "          40,  1617, 26356,  1676,   244,   251, 13509], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How did King Leopold II come to own  Congo?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.question1.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [03:59, 9185.46it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('data/glove.840B.300d.txt')\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[-300:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2195884 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76057/76057 [00:00<00:00, 135993.55it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "not_present_words = []\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    if embedding_vector is None:\n",
    "        not_present_words.append(word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15613"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(not_present_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DROPOUT=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question1 = Input(shape=(max_len,))\n",
    "question2 = Input(shape=(max_len,))\n",
    "\n",
    "q1 = Embedding(len(word_index) + 1, \n",
    "                 300, \n",
    "                 weights=[embedding_matrix], \n",
    "                 input_length=max_len, \n",
    "                 trainable=False)(question1)\n",
    "q1 = TimeDistributed(Dense(300, activation='relu'))(q1)\n",
    "q1 = Lambda(lambda x: K.max(x, axis=1), output_shape=(300, ))(q1)\n",
    "\n",
    "q2 = Embedding(len(word_index) + 1, \n",
    "                 300, \n",
    "                 weights=[embedding_matrix], \n",
    "                 input_length=max_len, \n",
    "                 trainable=False)(question2)\n",
    "q2 = TimeDistributed(Dense(300, activation='relu'))(q2)\n",
    "q2 = Lambda(lambda x: K.max(x, axis=1), output_shape=(300, ))(q2)\n",
    "\n",
    "merged = concatenate([q1,q2])\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "is_duplicate = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model(inputs=[question1,question2], outputs=is_duplicate)\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 294726 samples, validate on 32748 samples\n",
      "Epoch 1/25\n",
      " - 137s - loss: 0.5404 - acc: 0.7259 - val_loss: 0.5185 - val_acc: 0.7338\n",
      "Epoch 2/25\n",
      " - 135s - loss: 0.4886 - acc: 0.7605 - val_loss: 0.4652 - val_acc: 0.7701\n",
      "Epoch 3/25\n",
      " - 135s - loss: 0.4626 - acc: 0.7770 - val_loss: 0.4590 - val_acc: 0.7753\n",
      "Epoch 4/25\n",
      " - 135s - loss: 0.4397 - acc: 0.7905 - val_loss: 0.4423 - val_acc: 0.7847\n",
      "Epoch 5/25\n",
      " - 135s - loss: 0.4222 - acc: 0.8012 - val_loss: 0.4367 - val_acc: 0.7879\n",
      "Epoch 6/25\n",
      " - 132s - loss: 0.4077 - acc: 0.8106 - val_loss: 0.4607 - val_acc: 0.7703\n",
      "Epoch 7/25\n",
      " - 137s - loss: 0.3919 - acc: 0.8193 - val_loss: 0.4348 - val_acc: 0.7929\n",
      "Epoch 8/25\n",
      " - 134s - loss: 0.3779 - acc: 0.8276 - val_loss: 0.4354 - val_acc: 0.7909\n",
      "Epoch 9/25\n",
      " - 136s - loss: 0.3664 - acc: 0.8344 - val_loss: 0.4218 - val_acc: 0.7971\n",
      "Epoch 10/25\n",
      " - 135s - loss: 0.3537 - acc: 0.8417 - val_loss: 0.4241 - val_acc: 0.8049\n",
      "Epoch 11/25\n",
      " - 135s - loss: 0.3456 - acc: 0.8468 - val_loss: 0.4142 - val_acc: 0.8052\n",
      "Epoch 12/25\n",
      " - 135s - loss: 0.3361 - acc: 0.8515 - val_loss: 0.4146 - val_acc: 0.8057\n",
      "Epoch 13/25\n",
      " - 132s - loss: 0.3285 - acc: 0.8562 - val_loss: 0.4227 - val_acc: 0.7992\n",
      "Epoch 14/25\n",
      " - 132s - loss: 0.3192 - acc: 0.8604 - val_loss: 0.4246 - val_acc: 0.8046\n",
      "Epoch 15/25\n",
      " - 132s - loss: 0.3155 - acc: 0.8623 - val_loss: 0.4427 - val_acc: 0.7974\n",
      "Epoch 16/25\n",
      " - 132s - loss: 0.3072 - acc: 0.8665 - val_loss: 0.4275 - val_acc: 0.8033\n",
      "Epoch 17/25\n",
      " - 132s - loss: 0.3006 - acc: 0.8700 - val_loss: 0.4231 - val_acc: 0.8005\n",
      "Epoch 18/25\n",
      " - 136s - loss: 0.2959 - acc: 0.8722 - val_loss: 0.4253 - val_acc: 0.8087\n",
      "Epoch 19/25\n",
      " - 132s - loss: 0.2947 - acc: 0.8724 - val_loss: 0.4443 - val_acc: 0.8010\n",
      "Epoch 20/25\n",
      " - 131s - loss: 0.2842 - acc: 0.8781 - val_loss: 0.4471 - val_acc: 0.7987\n",
      "Epoch 21/25\n",
      " - 131s - loss: 0.2779 - acc: 0.8800 - val_loss: 0.4311 - val_acc: 0.8080\n",
      "Epoch 22/25\n",
      " - 135s - loss: 0.2795 - acc: 0.8802 - val_loss: 0.4253 - val_acc: 0.8110\n",
      "Epoch 23/25\n",
      " - 134s - loss: 0.2687 - acc: 0.8850 - val_loss: 0.4198 - val_acc: 0.8129\n",
      "Epoch 24/25\n",
      " - 131s - loss: 0.2657 - acc: 0.8869 - val_loss: 0.4612 - val_acc: 0.8088\n",
      "Epoch 25/25\n",
      " - 131s - loss: 0.2632 - acc: 0.8873 - val_loss: 0.4372 - val_acc: 0.8045\n"
     ]
    }
   ],
   "source": [
    "callbacks = [ModelCheckpoint(\"base_model4\", monitor='val_acc', save_best_only=True)]\n",
    "history = model.fit([x1_train, x2_train],\n",
    "                    x_train.is_duplicate.values,\n",
    "                    epochs=25,\n",
    "                    validation_data=([x1_valid, x2_valid], x_valid.is_duplicate.values),\n",
    "                    verbose=2,\n",
    "                    batch_size=32,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum validation accuracy = 0.8129 (epoch 23)\n"
     ]
    }
   ],
   "source": [
    "# Print best validation accuracy and epoch\n",
    "max_val_acc, idx = max((val, idx) for (idx, val) in enumerate(history.history['val_acc']))\n",
    "print('Maximum validation accuracy = {0:.4f} (epoch {1:d})'.format(max_val_acc, idx+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/model_test.csv\")\n",
    "test[\"question1\"] = test[\"question1\"].apply(lambda x: str(x))\n",
    "test[\"question2\"] = test[\"question2\"].apply(lambda x: str(x))\n",
    "test[\"question1\"] = test[\"question1\"].apply(lambda x: x.replace(\"'\", \"\"))\n",
    "test[\"question2\"] = test[\"question2\"].apply(lambda x: x.replace(\"'\", \"\"))\n",
    "\n",
    "\n",
    "x1_test = []\n",
    "process_questions(x1_test, test.question1.values, 'x1_test', test)\n",
    "\n",
    "x2_test = []\n",
    "process_questions(x2_test, test.question2.values, 'test', test)\n",
    "\n",
    "x1_test = tk_train.texts_to_sequences(x1_test)\n",
    "x1_test = sequence.pad_sequences(x1_test, maxlen=max_len)\n",
    "\n",
    "x2_test = tk_train.texts_to_sequences(x2_test)\n",
    "x2_test = sequence.pad_sequences(x2_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 81.0\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"base_model4\")\n",
    "loss, accuracy = model.evaluate([x1_test, x2_test], test.is_duplicate.values, verbose=0)\n",
    "print(\"Test Accuracy:\",round(accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
